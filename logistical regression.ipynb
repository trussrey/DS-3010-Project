{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821f0e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_type_id</th>\n",
       "      <th>language_type_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>type_id</th>\n",
       "      <th>show_id</th>\n",
       "      <th>production_country_type_id</th>\n",
       "      <th>origin_country_type_id</th>\n",
       "      <th>show_id</th>\n",
       "      <th>network_type_id</th>\n",
       "      <th>genre_type_id</th>\n",
       "      <th>...</th>\n",
       "      <th>show_id</th>\n",
       "      <th>language_type_id</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>show_id</th>\n",
       "      <th>created_by_type_id</th>\n",
       "      <th>show_id</th>\n",
       "      <th>genre_type_id</th>\n",
       "      <th>show_id</th>\n",
       "      <th>spoken_language_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "      <td>143.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>81691.000000</td>\n",
       "      <td>81691.000000</td>\n",
       "      <td>81691.000000</td>\n",
       "      <td>108295.000000</td>\n",
       "      <td>108295.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>113269.000000</td>\n",
       "      <td>113269.000000</td>\n",
       "      <td>162143.000000</td>\n",
       "      <td>162143.000000</td>\n",
       "      <td>162143.000000</td>\n",
       "      <td>31852.000000</td>\n",
       "      <td>143711.000000</td>\n",
       "      <td>143711.000000</td>\n",
       "      <td>111686.000000</td>\n",
       "      <td>111686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>114910.322569</td>\n",
       "      <td>91.124653</td>\n",
       "      <td>77.718084</td>\n",
       "      <td>98802.453557</td>\n",
       "      <td>1766.482441</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>103423.003938</td>\n",
       "      <td>67.533818</td>\n",
       "      <td>13.834356</td>\n",
       "      <td>2.407624</td>\n",
       "      <td>106075.281862</td>\n",
       "      <td>15926.500000</td>\n",
       "      <td>104532.616272</td>\n",
       "      <td>11.559734</td>\n",
       "      <td>103124.551788</td>\n",
       "      <td>32.155239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.42463</td>\n",
       "      <td>1.870829</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>64859.551114</td>\n",
       "      <td>61.557675</td>\n",
       "      <td>49.129215</td>\n",
       "      <td>68150.303014</td>\n",
       "      <td>949.279001</td>\n",
       "      <td>5.91608</td>\n",
       "      <td>...</td>\n",
       "      <td>69725.145748</td>\n",
       "      <td>35.461372</td>\n",
       "      <td>194.575049</td>\n",
       "      <td>3.479961</td>\n",
       "      <td>73262.593684</td>\n",
       "      <td>9195.024724</td>\n",
       "      <td>69542.151803</td>\n",
       "      <td>5.606986</td>\n",
       "      <td>69552.996633</td>\n",
       "      <td>25.264476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.5</td>\n",
       "      <td>36.50000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>70100.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>43085.500000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>5.75000</td>\n",
       "      <td>...</td>\n",
       "      <td>46067.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44058.500000</td>\n",
       "      <td>7963.750000</td>\n",
       "      <td>51062.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>46019.250000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>103794.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>88943.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>10.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>93070.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93688.000000</td>\n",
       "      <td>15926.500000</td>\n",
       "      <td>92646.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>92828.500000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.5</td>\n",
       "      <td>107.50000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>154643.500000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>132745.500000</td>\n",
       "      <td>2525.000000</td>\n",
       "      <td>15.25000</td>\n",
       "      <td>...</td>\n",
       "      <td>137024.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>155792.500000</td>\n",
       "      <td>23889.250000</td>\n",
       "      <td>137838.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>136679.750000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.0</td>\n",
       "      <td>143.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>242576.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>242576.000000</td>\n",
       "      <td>3398.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>242576.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>21857.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>242576.000000</td>\n",
       "      <td>31852.000000</td>\n",
       "      <td>242574.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>242576.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       link_type_id  language_type_id  status_id   type_id        show_id  \\\n",
       "count           3.0         143.00000   6.000000  7.000000   81691.000000   \n",
       "mean            2.0          72.00000   3.500000  4.000000  114910.322569   \n",
       "std             1.0          41.42463   1.870829  2.160247   64859.551114   \n",
       "min             1.0           1.00000   1.000000  1.000000       1.000000   \n",
       "25%             1.5          36.50000   2.250000  2.500000   70100.500000   \n",
       "50%             2.0          72.00000   3.500000  4.000000  103794.000000   \n",
       "75%             2.5         107.50000   4.750000  5.500000  154643.500000   \n",
       "max             3.0         143.00000   6.000000  7.000000  242576.000000   \n",
       "\n",
       "       production_country_type_id  origin_country_type_id        show_id  \\\n",
       "count                81691.000000            81691.000000  108295.000000   \n",
       "mean                    91.124653               77.718084   98802.453557   \n",
       "std                     61.557675               49.129215   68150.303014   \n",
       "min                      1.000000                1.000000       1.000000   \n",
       "25%                     30.000000               26.000000   43085.500000   \n",
       "50%                     89.000000               81.000000   88943.000000   \n",
       "75%                    157.000000              129.000000  132745.500000   \n",
       "max                    183.000000              160.000000  242576.000000   \n",
       "\n",
       "       network_type_id  genre_type_id  ...        show_id  language_type_id  \\\n",
       "count    108295.000000       20.00000  ...  113269.000000     113269.000000   \n",
       "mean       1766.482441       10.50000  ...  103423.003938         67.533818   \n",
       "std         949.279001        5.91608  ...   69725.145748         35.461372   \n",
       "min           1.000000        1.00000  ...       1.000000          1.000000   \n",
       "25%         968.000000        5.75000  ...   46067.000000         50.000000   \n",
       "50%        1900.000000       10.50000  ...   93070.000000         66.000000   \n",
       "75%        2525.000000       15.25000  ...  137024.000000         80.000000   \n",
       "max        3398.000000       20.00000  ...  242576.000000        143.000000   \n",
       "\n",
       "          vote_count   vote_average        show_id  created_by_type_id  \\\n",
       "count  162143.000000  162143.000000  162143.000000        31852.000000   \n",
       "mean       13.834356       2.407624  106075.281862        15926.500000   \n",
       "std       194.575049       3.479961   73262.593684         9195.024724   \n",
       "min         0.000000       0.000000       1.000000            1.000000   \n",
       "25%         0.000000       0.000000   44058.500000         7963.750000   \n",
       "50%         0.000000       0.000000   93688.000000        15926.500000   \n",
       "75%         1.000000       6.000000  155792.500000        23889.250000   \n",
       "max     21857.000000      10.000000  242576.000000        31852.000000   \n",
       "\n",
       "             show_id  genre_type_id        show_id  spoken_language_type_id  \n",
       "count  143711.000000  143711.000000  111686.000000            111686.000000  \n",
       "mean   104532.616272      11.559734  103124.551788                32.155239  \n",
       "std     69542.151803       5.606986   69552.996633                25.264476  \n",
       "min         1.000000       1.000000       1.000000                 1.000000  \n",
       "25%     51062.000000       7.000000   46019.250000                 6.000000  \n",
       "50%     92646.000000      12.000000   92828.500000                37.000000  \n",
       "75%    137838.000000      17.000000  136679.750000                53.000000  \n",
       "max    242574.000000      20.000000  242576.000000                74.000000  \n",
       "\n",
       "[8 rows x 43 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the folder containing cleaned CSV files\n",
    "folder_path = 'cleanedtvshows'\n",
    "\n",
    "# lists all cleaned CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# intiialize empty df\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# iterates through each cleaned CSV file\n",
    "for file_name in csv_files:\n",
    "    # reads cleaned CSV file into df\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # concatenate current df with combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "# descriptive statistics\n",
    "statistics = combined_df.describe()\n",
    "\n",
    "statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9931c521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 17406.95916955184\n"
     ]
    }
   ],
   "source": [
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # # Compute the correlation matrix\n",
    "# combined_df = combined_df[['show_id','name','status_id','status_name','vote_count','vote_average', \n",
    "#                            'type_id','type_name','popularity','number_of_seasons','genre_type_id',\n",
    "#                            'genre_name','production_country_type_id', 'in_production']]\n",
    "# # # corr = combined_df.corr(numeric_only=True)\n",
    "\n",
    "\n",
    "# # # # Plot a heatmap of the correlation matrix\n",
    "# # # plt.figure(figsize=(12, 8))\n",
    "# # # sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# # # plt.title('Correlation Heatmap')\n",
    "# # # plt.show()\n",
    "\n",
    "# # # Print correlation of features with the target variable ('success')\n",
    "# # # print(\"Correlation of features with 'success':\")\n",
    "# # # print(corr)\n",
    "# # # Assume combined_df is already defined and processed\n",
    "# # df = combined_df.dropna()\n",
    "# df = pd.get_dummies(df, columns=['status_name', 'name','genre_name', 'in_production'])\n",
    "\n",
    "\n",
    "# # # Split features and target variable\n",
    "# X = df.drop(['type_name'], axis=1)  # Remove non-predictive columns\n",
    "# y = (df['popularity'] + df['vote_average'] + df['number_of_seasons']) / 3  # Define success metric\n",
    "\n",
    "# # Train-test split (70% train, 30% test)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # # Initialize and train the logistic regression model\n",
    "# # logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# # logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# # # Predictions on the test set\n",
    "# # y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# # # Model evaluation\n",
    "# # accuracy = accuracy_score(y_test, y_pred)\n",
    "# # print(\"Accuracy:\", accuracy)\n",
    "# # print(\"\\nClassification Report:\")\n",
    "# # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Initialize and train the linear regression model\n",
    "# linear_model = LinearRegression()\n",
    "# linear_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predictions on the test set\n",
    "# y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# # Model evaluation\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# # Select two features for visualization\n",
    "# feature1 = 'feature1'\n",
    "# feature2 = 'feature2'\n",
    "\n",
    "# # Extract the selected features from the dataset\n",
    "# X_subset = X_train[[feature1, feature2]].values\n",
    "\n",
    "# # Fit logistic regression model on the subset of features\n",
    "# logreg_model_subset = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# logreg_model_subset.fit(X_subset, y_train)\n",
    "\n",
    "# # Plot decision boundary\n",
    "# h = .02  # step size in the mesh\n",
    "# x_min, x_max = X_subset[:, 0].min() - 1, X_subset[:, 0].max() + 1\n",
    "# # y_min, y_max = X_subset[:, 1].min() - 1, X_subset[:, 1].max() + 1\n",
    "# xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "# Z = logreg_model_subset.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# # Put the result into a color plot\n",
    "# Z = Z.reshape(xx.shape)\n",
    "# plt.figure(1, figsize=(8, 6))\n",
    "# plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
    "\n",
    "# # Plot the training points\n",
    "# plt.scatter(X_subset[:, 0], X_subset[:, 1], c=y_train, cmap=plt.cm.RdBu, edgecolors='k')\n",
    "\n",
    "# plt.xlabel(feature1)\n",
    "# plt.ylabel(feature2)\n",
    "# plt.title(\"Logistic Regression Decision Boundary\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e5daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       1.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "         2.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# # Define thresholds\n",
    "# low_threshold = np.percentile(y, 33)\n",
    "# high_threshold = np.percentile(y, 66)\n",
    "\n",
    "# # Assign labels based on thresholds\n",
    "# y_class = np.zeros_like(y)\n",
    "# y_class[y < low_threshold] = 0  # Low success\n",
    "# y_class[(y >= low_threshold) & (y < high_threshold)] = 1  # Medium success\n",
    "# y_class[y >= high_threshold] = 2  # High success\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Initialize and train the logistic regression model\n",
    "# logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predictions on the test set\n",
    "# y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# # Model evaluation\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbe89877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         1\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "         2.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.67      0.56         3\n",
      "weighted avg       0.50      0.67      0.56         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Compute the correlation matrix\n",
    "combined_df = combined_df[['vote_average', \n",
    "                           'type_name','popularity','number_of_seasons']]\n",
    "\n",
    "df = combined_df.dropna()\n",
    "# df = pd.get_dummies(df, columns=['status_name', 'name','genre_name', 'in_production'])\n",
    "\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(['type_name'], axis=1)  # Remove non-predictive columns\n",
    "y = (df['popularity'] + df['vote_average'] + df['number_of_seasons']) / 3  # Define success metric\n",
    "\n",
    "\n",
    "# Define thresholds\n",
    "low_threshold = np.percentile(y, 33)\n",
    "high_threshold = np.percentile(y, 66)\n",
    "\n",
    "# Assign labels based on thresholds\n",
    "y_class = np.zeros_like(y)\n",
    "y_class[y < low_threshold] = 0  # Low success\n",
    "y_class[(y >= low_threshold) & (y < high_threshold)] = 1  # Medium success\n",
    "y_class[y >= high_threshold] = 2  # High success\n",
    "\n",
    "# Split the dataset into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, train_size=0.7, test_size=0.3, random_state=42, stratify=y_class)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125eca22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
