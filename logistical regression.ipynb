{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9931c521",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 56.9 GiB for an array with shape (21587, 2831561) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvote_average\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_seasons\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Target variable\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Encode categorical variables if needed\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# For example, using one-hot encoding:\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(X)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Train-test split (80% train, 20% test)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:203\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    199\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    204\u001b[0m         col[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    205\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mpre,\n\u001b[0;32m    206\u001b[0m         prefix_sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m    207\u001b[0m         dummy_na\u001b[38;5;241m=\u001b[39mdummy_na,\n\u001b[0;32m    208\u001b[0m         sparse\u001b[38;5;241m=\u001b[39msparse,\n\u001b[0;32m    209\u001b[0m         drop_first\u001b[38;5;241m=\u001b[39mdrop_first,\n\u001b[0;32m    210\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[0;32m    212\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[0;32m    213\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:324\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     eye_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[1;32m--> 324\u001b[0m dummy_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(number_of_cols, dtype\u001b[38;5;241m=\u001b[39meye_dtype)\u001b[38;5;241m.\u001b[39mtake(codes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     dummy_mat[codes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 56.9 GiB for an array with shape (21587, 2831561) and data type bool"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Path to the folder containing cleaned CSV files\n",
    "folder_path = 'cleanedtvshows'\n",
    "\n",
    "# List all cleaned CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each cleaned CSV file\n",
    "for file_name in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Concatenate current DataFrame with combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Preprocessing: Drop irrelevant columns and handle missing values\n",
    "# For example:\n",
    "# df.drop(['irrelevant_column1', 'irrelevant_column2'], axis=1, inplace=True)\n",
    "# df.dropna(inplace=True)\n",
    "df = combined_df\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df.drop(columns=['show_id'])  # Features\n",
    "y = (df['vote_average']+df['popularity']+df['number_of_seasons'])/3  # Target variable\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "# For example, using one-hot encoding:\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Select two features for visualization\n",
    "feature1 = 'popularity'\n",
    "feature2 = 'vote_average'\n",
    "\n",
    "# Extract the selected features from the dataset\n",
    "X_subset = X_train[[feature1, feature2]].values\n",
    "\n",
    "# Fit logistic regression model on the subset of features\n",
    "logreg_model_subset = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model_subset.fit(X_subset, y_train)\n",
    "\n",
    "# Plot decision boundary\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X_subset[:, 0].min() - 1, X_subset[:, 0].max() + 1\n",
    "y_min, y_max = X_subset[:, 1].min() - 1, X_subset[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg_model_subset.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_subset[:, 0], X_subset[:, 1], c=y_train, cmap=plt.cm.RdBu, edgecolors='k')\n",
    "\n",
    "plt.xlabel(feature1)\n",
    "plt.ylabel(feature2)\n",
    "plt.title(\"Logistic Regression Decision Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5daf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
