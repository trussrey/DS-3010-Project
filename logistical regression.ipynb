{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821f0e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      6\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/DS 3010 Project/tvshows.zip\", 'r')\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "#zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/DS 3010 Project/tvshows.zip\", 'r')\n",
    "zip_file_path = 'content/drive/Shared with me/DS 3010 Project/tvshows.zip'\n",
    "\n",
    "extracted_folder_path = '/content/extracted_files/'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = '/content/drive/My Drive/DS 3010 Project/cleanedtvshows'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Iterate through each CSV file\n",
    "for file_name in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "      # Handle missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Save the cleaned DataFrame back to a CSV file\n",
    "    cleaned_file_path = os.path.join(folder_path, 'cleaned_' + file_name)\n",
    "    df.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Path to the folder containing cleaned CSV files\n",
    "folder_path = 'cleanedtvshows'\n",
    "\n",
    "# List all cleaned CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each cleaned CSV file\n",
    "for file_name in csv_files:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Concatenate current DataFrame with combined DataFrame\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Preprocessing: Drop irrelevant columns and handle missing values\n",
    "# For example:\n",
    "# df.drop(['irrelevant_column1', 'irrelevant_column2'], axis=1, inplace=True)\n",
    "# df.dropna(inplace=True)\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = combined_df.drop(columns=['show_id','name','status_id','status_name','vote_count','vote_average', \n",
    "                           'type_id','type_name','popularity','number_of_seasons','genre_type_id',\n",
    "                           'genre_name','production_country_type_id', 'in_production'])  # Features\n",
    "y = combined_df['show_id','name','status_id','status_name','vote_count','vote_average', \n",
    "                           'type_id','type_name','popularity','number_of_seasons','genre_type_id',\n",
    "                           'genre_name','production_country_type_id', 'in_production']  # Target variable\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "# For example, using one-hot encoding:\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Select two features for visualization\n",
    "feature1 = 'feature1'\n",
    "feature2 = 'feature2'\n",
    "\n",
    "# Extract the selected features from the dataset\n",
    "X_subset = X_train[[feature1, feature2]].values\n",
    "\n",
    "# Fit logistic regression model on the subset of features\n",
    "logreg_model_subset = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model_subset.fit(X_subset, y_train)\n",
    "\n",
    "# Plot decision boundary\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X_subset[:, 0].min() - 1, X_subset[:, 0].max() + 1\n",
    "y_min, y_max = X_subset[:, 1].min() - 1, X_subset[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg_model_subset.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_subset[:, 0], X_subset[:, 1], c=y_train, cmap=plt.cm.RdBu, edgecolors='k')\n",
    "\n",
    "plt.xlabel(feature1)\n",
    "plt.ylabel(feature2)\n",
    "plt.title(\"Logistic Regression Decision Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5daf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
